<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fashion MNIST Image Classification Project</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #fff;
            /* Set background to white */
        }

        header {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 1em;
        }

        main {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }

        h1 {
            color: #333;
            text-align: center;
            /* Center the h1 tag */
        }

        h2 {
            text-align: center;
            /* Center the Authors heading */
            margin-top: 20px;
        }

        h3 {
            color: #333;
        }

        a {
            color: #007BFF;
            text-decoration: none;
        }

        p {
            margin-bottom: 15px;
        }

        img {
            max-width: 100%;
            height: auto;
        }

        ul.authors-list {
            max-width: 800px;
            list-style: none;
            padding: 0;
            display: flex;
            justify-content: space-between;
            margin: 0 auto;
            /* Center the authors list */
        }

        ul.authors-list li {
            flex: 1;
            margin-right: 20px;
        }

        blockquote {
            margin: 0;
            padding: 10px;
            background-color: #f9f9f9;
            border-left: 4px solid #ccc;
            margin-bottom: 15px;
        }

        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 1em;
            position: fixed;
            bottom: 0;
            width: 100%;
        }

        .center {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
        }
    </style>
</head>

<body>

    <h1>
        Fashion MNIST Image Classification Project
    </h1>
    <h2>Authors</h2>
    <ul class="authors-list">
        <li>
            <strong>Yamini Preethi Kamisetty</strong><br>
            Texas A&M University<br>
            College Station, United States<br>
            <a href="mailto:yamini_preethi_k@tamu.edu">yamini_preethi_k@tamu.edu</a>
        </li>
        <li>
            <strong>Bhavyasree Mohan</strong><br>
            Texas A&M University<br>
            College Station, United States<br>
            <a href="mailto:bhavya_0108@tamu.edu">bhavya0108@tamu.edu</a>
        </li>
        <li>
            <strong>Sri Harsha Parimi Venkata</strong><br>
            Texas A&M University<br>
            College Station, United States<br>
            <a href="mailto:parimi@tamu.edu">parimi@tamu.edu</a>
        </li>
    </ul>
    <main>
        <article>
            <p>Welcome to the Fashion MNIST Image Classification Project. In this project, we explore the process of
                building an XGBoost and Convolutional Neural Network (CNN) using PyTorch to classify images from the
                Fashion MNIST
                dataset.
            </p>

            <!-- <img src="fig1.png" alt="Fashion MNIST"> -->
            <img src="static/fig1.png" alt="Fashion MNIST" class="center">
            <figcaption class="center">Fashion MNIST Dataset Example</figcaption>

            <h2>Abstract</h2>
            <p>This project dives into the architecture of the model, the training process, and interpretability using
                LIME. Whether you are a beginner in deep learning or looking to implement image classification, this
                tutorial will guide you through the steps to create an effective and interpretable model.


                Data mining, machine learning and deep learning are being extensively used in today’s world across
                various sectors like e-commerce, fashion, automobile industry and others. With enormous data available
                in the fashion industry, there has beena rapid increase in the usage of the data science technologies in
                fashion e-commerce to address several problems like clothing classification, recognition, and
                recommendations. This paper presents various approaches to perform clothing classification using the
                Fashion MNIST dataset. The study aims to classify the images into ten categories. In this paper,
                classical machine learning algorithms like XGBoost and Random Forest have been used as baseline models
                to perform the classification. Deep learning algorithms like Convolutional Neural Networks (CNN) are
                utilized to perform this image classification task. The paper also aims at the interpretability of these
                models predictions by using various methods including LIME and SHAP.
            </p>

            <h2>Model Outline</h2>

            <p>
                This project is centered on employing two methodologies: <br>
                1. <u><b>XGBoost</b></u>:
                The XGBoost classifier is employed through the XGBoost library.Subsequently, hyperparameter tuning is
                conducted using grid search cross-validation to obtain optimal parameters for the XGBoost classifier.
                This comprehensive approach ensures the robustness and efficacy of the baseline model in the context of
                the study. <br>
                2. <u><b>CNN</b></u>: The CNN model has been built based on the LeNet architecture. It has 5 layers - 2 convolutional
                and 3 fully connected as shown below.
            <pre>
                    ----------------------------------------------------------------
                    Layer (type)        Output Shape    Param #
                    ================================================================
                    Conv2d-1            [100, 6, 28, 28]    156
                    ReLU-2              [100, 6, 28, 28]    0
                    AvgPool2d-3         [100, 6, 14, 14]    0
                    Conv2d-4            [100, 16, 10, 10]    2,416
                    ReLU-5              [100, 16, 10, 10]    0
                    AvgPool2d-6         [100, 16, 5, 5]    0
                    Linear-7            [100, 120]    48,120
                    ReLU-8              [100, 120]    0
                    Linear-9            [100, 64]    7,744
                    ReLU-10             [100, 64]    0
                    Linear-11           [100, 10]    650
                    ================================================================
                    Total params: 59,086
                    Trainable params: 59,086
                    Non-trainable params: 0
                    ----------------------------------------------------------------
                    Input size (MB): 0.30
                    Forward/backward pass size (MB): 11.11
                    Params size (MB): 0.23
                    Estimated Total Size (MB): 11.63
                    ----------------------------------------------------------------
                </pre>
            </p>

            <h2>Training and Model Evaluation</h2>
            Steps followed in the Training and Evaluation process: <br>

            1. The data is split into train, test and validation sets where train set is used for model training,
            validation set is used for cross validating the trained model and test set for measuring model performance.
            The data has also been normalized using PyTorch which scales the input down to [0,1] for the CNN model. <br>

            2. To obtain the best hyperparameters of the model we have used GridSearch. GridSerach is a technique that
            attempts to find out the optimum values of the hyperparameters by searching exhaustinvely through a
            manually specified subset of hyperparameters<br>

            3. Using instanciated XGBoost and CNN models on the training dataset, training was carried out. While
            checking the accuracy on the test data to make sure that the loss is decreasing <br>

            4. After training the XGBoost Classifier and CNN model on the Fashion MNIST dataset the following results
            have been obtained.<br>
            <pre>
                For XGBoost,
                Accuracy on training set - 98.6%
                Accuracy on test set - 89.43%
            </pre>
            <pre>
                For CNN,
                Accuracy on training set - 95.07%
                Accuracy on test set - 91.26%
            </pre>
            <p>
                The accuracy has also been evaluated for each class using CNN and below are the results:
            <pre>
                T-shirt/Top: 87.70% Pullover: 88.00% 
                Coat: 86.40%        Shirt: 73.80%
                Bag: 98.60%         Trouser: 97.70% 
                Dress: 90.60%       Sandal: 98.10%
                Sneaker: 95.60%     Ankle Boot: 96.20%
            </pre>
            </p>
            <img src="static/fig2.jpeg" width="350" height="500">
            <img src="static/fig3.png" width="350" height="500">

            <img src="static/fig4.png" width="600" height="500">
            <p>
                To validate the real-world applicability of our findings, an out-of-sample image sourced from Google was
                subjected to CNN. The CNN, being a more complex and adaptive architecture, demonstrated for CNN superior
                performance, reaffirming its robustness in handling diverse and nuanced visual patterns.
            </p>
            <img src="static/fig5.jpeg" width="350" height="500">
            <img src="static/fig6.jpeg" width="350" height="500">

            <h2>Conclusion</h2>
            <p>In the exploration of the Fashion MNIST dataset, a comparative study between Convolutional Neural
                Networks (CNN) and XGBoost has unveiled intriguing insights into their performance. After observing the
                performance of two models, it is clear that CNN outperforms XGBoost.
                To validate the real-world applicability of our findings, an out-of-sample image sourced from Google was
                subjected to CNN. The CNN, being a more complex and adaptive architecture, demonstrated superior
                performance, reaffirming its robustness in handling diverse and nuanced visual patterns.<br>

                Classes such as 't-shirt/top,' 'pullover,' and 'shirt' exhibited lower accuracy. This trend prompted a
                deeper investigation into the interpretability of model decisions.
                The human intuition that these classes share similar shapes was validated through advanced
                interpretability tools such as SHAP and LIME.

                The future work is to focus on refining the model to better differentiate between certain classes with
                lower accuracy, notably 't-shirt/top,' 'pullover,' and 'shirt.' This effort aims to enhance the model's
                precision within these specific categories, contributing to an overall improvement in classification
                accuracy..</p>

            <blockquote>
                <p>There ain't no such thing as a free lunch”</p>
                <cite>— David Wolpert and William Macready</cite>
            </blockquote>

            <p>Thank you for joining us on this journey. If you have any questions or comments, email
                us at <a href="#"> parimi@tamu.edu</a>.</p>

        </article>
    </main>

    <!-- <footer>
        &copy; 2023 Fashion MNIST Project. All rights reserved.
    </footer> -->

</body>

</html>